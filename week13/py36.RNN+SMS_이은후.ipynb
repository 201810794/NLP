{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 하이퍼파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "num_epochs=10\n",
    "\n",
    "word_vec_size=256\n",
    "dropout_p=0.3\n",
    "\n",
    "hidden_size=512\n",
    "num_layers=4\n",
    "\n",
    "learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.4.0\n",
      "  Downloading torchtext-0.4.0-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 2.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext==0.4.0) (2.22.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext==0.4.0) (4.42.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext==0.4.0) (1.18.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext==0.4.0) (1.14.0)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext==0.4.0) (1.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext==0.4.0) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext==0.4.0) (1.25.10)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext==0.4.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext==0.4.0) (2.8)\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.4.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SMS train, test dataset 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = DataLoader(\n",
    "    train_fn='./sms.maxlen.uniq.shuf.train.tsv',\n",
    "    batch_size=batch_size,\n",
    "    valid_ratio=.2,\n",
    "    device=-1,\n",
    "    max_vocab=999999,\n",
    "    min_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loaders = DataLoader(\n",
    "    train_fn='./sms.maxlen.uniq.shuf.test.tsv',\n",
    "    batch_size=batch_size,\n",
    "    valid_ratio=.01,\n",
    "    device=-1,\n",
    "    max_vocab=999999,\n",
    "    min_freq=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 대략적인 데이터 형태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|train| = 3722 |valid| = 930\n",
      "|vobab| = 1533 |classes| = 2\n"
     ]
    }
   ],
   "source": [
    "print(\"|train| =\", len(loaders.train_loader.dataset),\n",
    "     '|valid| =', len(loaders.valid_loader.dataset))\n",
    "\n",
    "vocab_size=len(loaders.text.vocab)\n",
    "num_classes=len(loaders.label.vocab)\n",
    "print('|vobab| =', vocab_size, '|classes| =', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 데이터 로드함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      " 한 번에 로드되는 데이터 크기: 128\n",
      "label:  0\n",
      "text:  (10,)\n",
      "label:  0\n",
      "text:  (10,)\n",
      "label:  0\n",
      "text:  (10,)\n",
      "[1]\n",
      " 한 번에 로드되는 데이터 크기: 128\n",
      "label:  0\n",
      "text:  (4,)\n",
      "label:  0\n",
      "text:  (4,)\n",
      "label:  0\n",
      "text:  (4,)\n",
      "[2]\n",
      " 한 번에 로드되는 데이터 크기: 128\n",
      "label:  0\n",
      "text:  (7,)\n",
      "label:  0\n",
      "text:  (7,)\n",
      "label:  0\n",
      "text:  (7,)\n",
      "[3]\n",
      " 한 번에 로드되는 데이터 크기: 10\n",
      "label:  0\n",
      "text:  (60,)\n",
      "label:  0\n",
      "text:  (60,)\n",
      "label:  0\n",
      "text:  (60,)\n"
     ]
    }
   ],
   "source": [
    "n=3\n",
    "for i, data in enumerate(loaders.train_loader):\n",
    "    labels=data.label\n",
    "    texts=data.text\n",
    "    \n",
    "    if i>n:\n",
    "        break\n",
    "    \n",
    "    print (\"[%d]\" %i)\n",
    "    print(\" 한 번에 로드되는 데이터 크기:\", len(labels))\n",
    "    \n",
    "    for j in range(n):\n",
    "        label=labels[j].numpy()\n",
    "        text=texts[j].numpy()\n",
    "        print(\"label: \",label)\n",
    "        print(\"text: \", text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 word_vec_size,\n",
    "                 hidden_size,\n",
    "                 n_classes,\n",
    "                 num_layers=4,\n",
    "                 dropout_p=0.3):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size=input_size\n",
    "        self.word_vec_size=word_vec_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.n_classes=n_classes\n",
    "        self.num_layers=num_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        self.emb=nn.Embedding(input_size, word_vec_size)\n",
    "        \n",
    "        self.lstm=nn.LSTM(input_size=word_vec_size,\n",
    "                          hidden_size=hidden_size, \n",
    "                          num_layers=num_layers,\n",
    "                          dropout = dropout_p,\n",
    "                          batch_first=True,\n",
    "                          bidirectional=True)\n",
    "        self.fc=nn.Linear(hidden_size*2, num_classes)\n",
    "        self.activation=nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.emb(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        \n",
    "        out=self.activation(self.fc(x[:, -1]))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=vocab_size,\n",
    "            word_vec_size=word_vec_size,\n",
    "            hidden_size=hidden_size,\n",
    "            n_classes=num_classes,\n",
    "            num_layers=num_layers,\n",
    "            dropout_p=dropout_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeAccr(dloader, imodel):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for i, data in enumerate(dloader):\n",
    "        texts=data.text.to(device)\n",
    "        labels=data.label.to(device)\n",
    "         \n",
    "        output=model(texts)\n",
    "        _, output_index = torch.max(output,1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (output_index == labels).sum().float()\n",
    "        \n",
    "    model.train()\n",
    "    return (100*correct/total).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test data: 13.01\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of test data: %.2f\" %ComputeAccr(loaders.valid_loader, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [1/10], Step [10/30], Loss: 1.1330, Accr: 86.99\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [1/10], Step [20/30], Loss: 1.2169, Accr: 86.99\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [1/10], Step [30/30], Loss: 1.3768, Accr: 86.99\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [2/10], Step [10/30], Loss: 0.9219, Accr: 86.88\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [2/10], Step [20/30], Loss: 0.2145, Accr: 86.99\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [2/10], Step [30/30], Loss: 0.6151, Accr: 88.92\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [3/10], Step [10/30], Loss: 0.2677, Accr: 92.04\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [3/10], Step [20/30], Loss: 0.0324, Accr: 90.97\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [3/10], Step [30/30], Loss: 0.0558, Accr: 93.12\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [4/10], Step [10/30], Loss: 0.2058, Accr: 88.92\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [4/10], Step [20/30], Loss: 0.8499, Accr: 96.13\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [4/10], Step [30/30], Loss: 0.1424, Accr: 91.40\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [5/10], Step [10/30], Loss: 0.0065, Accr: 91.40\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [5/10], Step [20/30], Loss: 0.1875, Accr: 94.09\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [5/10], Step [30/30], Loss: 0.1925, Accr: 95.27\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [6/10], Step [10/30], Loss: 0.0107, Accr: 96.24\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [6/10], Step [20/30], Loss: 0.0109, Accr: 96.88\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [6/10], Step [30/30], Loss: 0.1996, Accr: 96.56\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [7/10], Step [10/30], Loss: 0.0137, Accr: 96.99\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [7/10], Step [20/30], Loss: 0.1434, Accr: 96.45\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [7/10], Step [30/30], Loss: 0.0078, Accr: 96.77\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [8/10], Step [10/30], Loss: 0.0257, Accr: 96.88\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [8/10], Step [20/30], Loss: 0.0003, Accr: 96.99\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [8/10], Step [30/30], Loss: 0.0999, Accr: 96.45\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [9/10], Step [10/30], Loss: 0.0180, Accr: 96.88\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [9/10], Step [20/30], Loss: 0.0241, Accr: 97.42\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [9/10], Step [30/30], Loss: 0.0007, Accr: 96.99\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [10/10], Step [10/30], Loss: 0.0852, Accr: 95.91\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [10/10], Step [20/30], Loss: 0.1047, Accr: 96.56\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [10/10], Step [30/30], Loss: 0.1048, Accr: 96.77\n"
     ]
    }
   ],
   "source": [
    "total_step = len(loaders.train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(loaders.train_loader):\n",
    "        texts=data.text.to(device)\n",
    "        labels=data.label.to(device)\n",
    "        \n",
    "        print(\"[%d]\" %i)\n",
    "        \n",
    "        outputs=model(texts)\n",
    "        loss=loss_func(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i+1)%10 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accr: {:.2f}'\n",
    "                 .format(epoch+1, num_epochs, i+1, total_step, loss.item(),\n",
    "                        ComputeAccr(loaders.valid_loader, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Valid Data: 96.77\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Valid Data: %.2f\" %ComputeAccr(loaders.valid_loader, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 학습된 파라미터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "netname = './rnn_weight.pkl'\n",
    "torch.save(model, netname, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 학습된 파라미터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Valid Data: 96.77\n"
     ]
    }
   ],
   "source": [
    "netname = './rnn_weight.pkl'\n",
    "model = torch.load(netname)\n",
    "\n",
    "print(\"Accuracy of Valid Data: %.2f\" %ComputeAccr(loaders.valid_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
